{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyDenseNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxtr_K2OMleu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from google.colab import files\n",
        "from torchsummary import summary\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ata8RVyZGIB6"
      },
      "source": [
        "## Bottleneck\n",
        "- use bottleneck block instead of normal dense block\n",
        "- to reduce feature map insert 1x1 conv layer before 3x3 conv layer\n",
        "- also increase computational efficiency\n",
        "- reference\n",
        "    - [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993v5.pdf) paper\n",
        "\n",
        "> BatchNorm(BN) → relu → 1x1 Conv → BN → relu → 3x3 Conv\n",
        "\n",
        "- for 1x1 Conv refering the paper, produce 4 * growth rate \n",
        "- add Dropout layer to prevent overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMNrRTXt9NFv"
      },
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_plane, growth_rate, droprate):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_plane)\n",
        "        self.conv1 = nn.Conv2d(in_plane, 4*growth_rate, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size = 3, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.droprate = droprate\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)        \n",
        "\n",
        "        return torch.cat([out, x], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK1bceuUHnSN"
      },
      "source": [
        "## TransitionBlock\n",
        "- in DenseNet, use transition block for **compression**\n",
        "- therefore, use 2 x 2 average pooling\n",
        "\n",
        "> BN → relu → 1 x 1 Conv → 2 x 2 Avg Pooling\n",
        "\n",
        "- add Dropout layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GPI9F1yByAD"
      },
      "source": [
        "class TransitionBlock(nn.Module):\n",
        "    def __init__(self, in_plane, out_plane, droprate):\n",
        "        super(TransitionBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_plane)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_plane, out_plane, kernel_size=1, stride=1, bias=False)\n",
        "        self.droprate = droprate\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = F.dropout(out, p=self.droprate, training=self.training, inplace=False)\n",
        "        \n",
        "        return F.avg_pool2d(out, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HriNzTDyI2N7"
      },
      "source": [
        "## DenseNet\n",
        "- make DenseNet using Bottleneck and transition block\n",
        "- refering the paper, \n",
        "    - set θ as 0.5, growth rate as 12\n",
        "    - set 1st 3 x 3 Conv layer's output channels as twice the growth rate\n",
        "    - for Dense121, \n",
        "        - no. of Dense block: 6 12 24 16 \n",
        "\n",
        "> conv → dense1 → transition1 → dense2 → transition2 → dense3 → transition3 → dense4 → classification layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMZaMu1CwHS"
      },
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, droprate, block=BottleneckBlock, growth_rate=12, num_classes=10, reduction=0.5):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "        \n",
        "\n",
        "        in_plane = 2 * growth_rate\n",
        "        self.conv1 = nn.Conv2d(3, in_plane, kernel_size = 3, padding=1, bias=False)\n",
        "\n",
        "        # 1st Dense & Transition\n",
        "        self.dense1 = self.make_dense_block(block, in_plane, 6, droprate)\n",
        "        in_plane += 6 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans1 = TransitionBlock(in_plane, out_plane, droprate)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 2nd Dense & Transition\n",
        "        self.dense2 = self.make_dense_block(block, in_plane, 12,droprate)\n",
        "        in_plane += 12 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans2 = TransitionBlock(in_plane, out_plane, droprate)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 3rd Dense & Transition\n",
        "        self.dense3 = self.make_dense_block(block, in_plane, 24, droprate)\n",
        "        in_plane += 24 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans3 = TransitionBlock(in_plane, out_plane, droprate)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 4th Dense\n",
        "        self.dense4 = self.make_dense_block(block, in_plane, 16, droprate)\n",
        "        in_plane += 16 * growth_rate\n",
        "        \n",
        "        self.bn = nn.BatchNorm2d(in_plane)\n",
        "        self.fc = nn.Linear(in_plane, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. /n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "       \n",
        "\n",
        "    def make_dense_block(self, block, in_plane, nblock, droprate):\n",
        "        layers=[]\n",
        "        for i in range(nblock):\n",
        "            layers.append(block(in_plane, self.growth_rate, droprate))\n",
        "            in_plane += self.growth_rate\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 32 x 32\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        # 32 x 32\n",
        "        out = self.dense1(out)\n",
        "        out = self.trans1(out) # 32 -> 16\n",
        "        \n",
        "        # 16 x 16\n",
        "        out = self.dense2(out)\n",
        "        out = self.trans2(out) # 16 -> 8\n",
        "        \n",
        "        # 8 x 8\n",
        "        out = self.dense3(out)\n",
        "        out = self.trans3(out) # 8 -> 4\n",
        "\n",
        "        out = self.dense4(out)\n",
        "\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HYIla_ZMQ32"
      },
      "source": [
        "model = DenseNet(droprate=0.2)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMK5LWzbQPMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac63d242-7bc5-4432-f219-4536d78a7cb6"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (dense1): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans1): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense2): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans2): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense3): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans3): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense4): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc): Linear(in_features=384, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOG0d9CBNRR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938061a2-4ce0-4a80-ec0e-c8905e1b87d8"
      },
      "source": [
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 32, 32]             648\n",
            "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
            "              ReLU-3           [-1, 24, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              ReLU-6           [-1, 48, 32, 32]               0\n",
            "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
            "   BottleneckBlock-8           [-1, 36, 32, 32]               0\n",
            "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
            "             ReLU-10           [-1, 36, 32, 32]               0\n",
            "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
            "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
            "             ReLU-13           [-1, 48, 32, 32]               0\n",
            "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-15           [-1, 48, 32, 32]               0\n",
            "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
            "             ReLU-17           [-1, 48, 32, 32]               0\n",
            "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
            "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
            "             ReLU-20           [-1, 48, 32, 32]               0\n",
            "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-22           [-1, 60, 32, 32]               0\n",
            "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
            "             ReLU-24           [-1, 60, 32, 32]               0\n",
            "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
            "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
            "             ReLU-27           [-1, 48, 32, 32]               0\n",
            "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-29           [-1, 72, 32, 32]               0\n",
            "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
            "             ReLU-31           [-1, 72, 32, 32]               0\n",
            "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
            "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
            "             ReLU-34           [-1, 48, 32, 32]               0\n",
            "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-36           [-1, 84, 32, 32]               0\n",
            "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
            "             ReLU-38           [-1, 84, 32, 32]               0\n",
            "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
            "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
            "             ReLU-41           [-1, 48, 32, 32]               0\n",
            "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-43           [-1, 96, 32, 32]               0\n",
            "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
            "             ReLU-45           [-1, 96, 32, 32]               0\n",
            "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
            "  TransitionBlock-47           [-1, 48, 16, 16]               0\n",
            "      BatchNorm2d-48           [-1, 48, 16, 16]              96\n",
            "             ReLU-49           [-1, 48, 16, 16]               0\n",
            "           Conv2d-50           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-51           [-1, 48, 16, 16]              96\n",
            "             ReLU-52           [-1, 48, 16, 16]               0\n",
            "           Conv2d-53           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-54           [-1, 60, 16, 16]               0\n",
            "      BatchNorm2d-55           [-1, 60, 16, 16]             120\n",
            "             ReLU-56           [-1, 60, 16, 16]               0\n",
            "           Conv2d-57           [-1, 48, 16, 16]           2,880\n",
            "      BatchNorm2d-58           [-1, 48, 16, 16]              96\n",
            "             ReLU-59           [-1, 48, 16, 16]               0\n",
            "           Conv2d-60           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-61           [-1, 72, 16, 16]               0\n",
            "      BatchNorm2d-62           [-1, 72, 16, 16]             144\n",
            "             ReLU-63           [-1, 72, 16, 16]               0\n",
            "           Conv2d-64           [-1, 48, 16, 16]           3,456\n",
            "      BatchNorm2d-65           [-1, 48, 16, 16]              96\n",
            "             ReLU-66           [-1, 48, 16, 16]               0\n",
            "           Conv2d-67           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-68           [-1, 84, 16, 16]               0\n",
            "      BatchNorm2d-69           [-1, 84, 16, 16]             168\n",
            "             ReLU-70           [-1, 84, 16, 16]               0\n",
            "           Conv2d-71           [-1, 48, 16, 16]           4,032\n",
            "      BatchNorm2d-72           [-1, 48, 16, 16]              96\n",
            "             ReLU-73           [-1, 48, 16, 16]               0\n",
            "           Conv2d-74           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-75           [-1, 96, 16, 16]               0\n",
            "      BatchNorm2d-76           [-1, 96, 16, 16]             192\n",
            "             ReLU-77           [-1, 96, 16, 16]               0\n",
            "           Conv2d-78           [-1, 48, 16, 16]           4,608\n",
            "      BatchNorm2d-79           [-1, 48, 16, 16]              96\n",
            "             ReLU-80           [-1, 48, 16, 16]               0\n",
            "           Conv2d-81           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-82          [-1, 108, 16, 16]               0\n",
            "      BatchNorm2d-83          [-1, 108, 16, 16]             216\n",
            "             ReLU-84          [-1, 108, 16, 16]               0\n",
            "           Conv2d-85           [-1, 48, 16, 16]           5,184\n",
            "      BatchNorm2d-86           [-1, 48, 16, 16]              96\n",
            "             ReLU-87           [-1, 48, 16, 16]               0\n",
            "           Conv2d-88           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-89          [-1, 120, 16, 16]               0\n",
            "      BatchNorm2d-90          [-1, 120, 16, 16]             240\n",
            "             ReLU-91          [-1, 120, 16, 16]               0\n",
            "           Conv2d-92           [-1, 48, 16, 16]           5,760\n",
            "      BatchNorm2d-93           [-1, 48, 16, 16]              96\n",
            "             ReLU-94           [-1, 48, 16, 16]               0\n",
            "           Conv2d-95           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-96          [-1, 132, 16, 16]               0\n",
            "      BatchNorm2d-97          [-1, 132, 16, 16]             264\n",
            "             ReLU-98          [-1, 132, 16, 16]               0\n",
            "           Conv2d-99           [-1, 48, 16, 16]           6,336\n",
            "     BatchNorm2d-100           [-1, 48, 16, 16]              96\n",
            "            ReLU-101           [-1, 48, 16, 16]               0\n",
            "          Conv2d-102           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-103          [-1, 144, 16, 16]               0\n",
            "     BatchNorm2d-104          [-1, 144, 16, 16]             288\n",
            "            ReLU-105          [-1, 144, 16, 16]               0\n",
            "          Conv2d-106           [-1, 48, 16, 16]           6,912\n",
            "     BatchNorm2d-107           [-1, 48, 16, 16]              96\n",
            "            ReLU-108           [-1, 48, 16, 16]               0\n",
            "          Conv2d-109           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-110          [-1, 156, 16, 16]               0\n",
            "     BatchNorm2d-111          [-1, 156, 16, 16]             312\n",
            "            ReLU-112          [-1, 156, 16, 16]               0\n",
            "          Conv2d-113           [-1, 48, 16, 16]           7,488\n",
            "     BatchNorm2d-114           [-1, 48, 16, 16]              96\n",
            "            ReLU-115           [-1, 48, 16, 16]               0\n",
            "          Conv2d-116           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-117          [-1, 168, 16, 16]               0\n",
            "     BatchNorm2d-118          [-1, 168, 16, 16]             336\n",
            "            ReLU-119          [-1, 168, 16, 16]               0\n",
            "          Conv2d-120           [-1, 48, 16, 16]           8,064\n",
            "     BatchNorm2d-121           [-1, 48, 16, 16]              96\n",
            "            ReLU-122           [-1, 48, 16, 16]               0\n",
            "          Conv2d-123           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-124          [-1, 180, 16, 16]               0\n",
            "     BatchNorm2d-125          [-1, 180, 16, 16]             360\n",
            "            ReLU-126          [-1, 180, 16, 16]               0\n",
            "          Conv2d-127           [-1, 48, 16, 16]           8,640\n",
            "     BatchNorm2d-128           [-1, 48, 16, 16]              96\n",
            "            ReLU-129           [-1, 48, 16, 16]               0\n",
            "          Conv2d-130           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-131          [-1, 192, 16, 16]               0\n",
            "     BatchNorm2d-132          [-1, 192, 16, 16]             384\n",
            "            ReLU-133          [-1, 192, 16, 16]               0\n",
            "          Conv2d-134           [-1, 96, 16, 16]          18,432\n",
            " TransitionBlock-135             [-1, 96, 8, 8]               0\n",
            "     BatchNorm2d-136             [-1, 96, 8, 8]             192\n",
            "            ReLU-137             [-1, 96, 8, 8]               0\n",
            "          Conv2d-138             [-1, 48, 8, 8]           4,608\n",
            "     BatchNorm2d-139             [-1, 48, 8, 8]              96\n",
            "            ReLU-140             [-1, 48, 8, 8]               0\n",
            "          Conv2d-141             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-142            [-1, 108, 8, 8]               0\n",
            "     BatchNorm2d-143            [-1, 108, 8, 8]             216\n",
            "            ReLU-144            [-1, 108, 8, 8]               0\n",
            "          Conv2d-145             [-1, 48, 8, 8]           5,184\n",
            "     BatchNorm2d-146             [-1, 48, 8, 8]              96\n",
            "            ReLU-147             [-1, 48, 8, 8]               0\n",
            "          Conv2d-148             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-149            [-1, 120, 8, 8]               0\n",
            "     BatchNorm2d-150            [-1, 120, 8, 8]             240\n",
            "            ReLU-151            [-1, 120, 8, 8]               0\n",
            "          Conv2d-152             [-1, 48, 8, 8]           5,760\n",
            "     BatchNorm2d-153             [-1, 48, 8, 8]              96\n",
            "            ReLU-154             [-1, 48, 8, 8]               0\n",
            "          Conv2d-155             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-156            [-1, 132, 8, 8]               0\n",
            "     BatchNorm2d-157            [-1, 132, 8, 8]             264\n",
            "            ReLU-158            [-1, 132, 8, 8]               0\n",
            "          Conv2d-159             [-1, 48, 8, 8]           6,336\n",
            "     BatchNorm2d-160             [-1, 48, 8, 8]              96\n",
            "            ReLU-161             [-1, 48, 8, 8]               0\n",
            "          Conv2d-162             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-163            [-1, 144, 8, 8]               0\n",
            "     BatchNorm2d-164            [-1, 144, 8, 8]             288\n",
            "            ReLU-165            [-1, 144, 8, 8]               0\n",
            "          Conv2d-166             [-1, 48, 8, 8]           6,912\n",
            "     BatchNorm2d-167             [-1, 48, 8, 8]              96\n",
            "            ReLU-168             [-1, 48, 8, 8]               0\n",
            "          Conv2d-169             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-170            [-1, 156, 8, 8]               0\n",
            "     BatchNorm2d-171            [-1, 156, 8, 8]             312\n",
            "            ReLU-172            [-1, 156, 8, 8]               0\n",
            "          Conv2d-173             [-1, 48, 8, 8]           7,488\n",
            "     BatchNorm2d-174             [-1, 48, 8, 8]              96\n",
            "            ReLU-175             [-1, 48, 8, 8]               0\n",
            "          Conv2d-176             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-177            [-1, 168, 8, 8]               0\n",
            "     BatchNorm2d-178            [-1, 168, 8, 8]             336\n",
            "            ReLU-179            [-1, 168, 8, 8]               0\n",
            "          Conv2d-180             [-1, 48, 8, 8]           8,064\n",
            "     BatchNorm2d-181             [-1, 48, 8, 8]              96\n",
            "            ReLU-182             [-1, 48, 8, 8]               0\n",
            "          Conv2d-183             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-184            [-1, 180, 8, 8]               0\n",
            "     BatchNorm2d-185            [-1, 180, 8, 8]             360\n",
            "            ReLU-186            [-1, 180, 8, 8]               0\n",
            "          Conv2d-187             [-1, 48, 8, 8]           8,640\n",
            "     BatchNorm2d-188             [-1, 48, 8, 8]              96\n",
            "            ReLU-189             [-1, 48, 8, 8]               0\n",
            "          Conv2d-190             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-191            [-1, 192, 8, 8]               0\n",
            "     BatchNorm2d-192            [-1, 192, 8, 8]             384\n",
            "            ReLU-193            [-1, 192, 8, 8]               0\n",
            "          Conv2d-194             [-1, 48, 8, 8]           9,216\n",
            "     BatchNorm2d-195             [-1, 48, 8, 8]              96\n",
            "            ReLU-196             [-1, 48, 8, 8]               0\n",
            "          Conv2d-197             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-198            [-1, 204, 8, 8]               0\n",
            "     BatchNorm2d-199            [-1, 204, 8, 8]             408\n",
            "            ReLU-200            [-1, 204, 8, 8]               0\n",
            "          Conv2d-201             [-1, 48, 8, 8]           9,792\n",
            "     BatchNorm2d-202             [-1, 48, 8, 8]              96\n",
            "            ReLU-203             [-1, 48, 8, 8]               0\n",
            "          Conv2d-204             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-205            [-1, 216, 8, 8]               0\n",
            "     BatchNorm2d-206            [-1, 216, 8, 8]             432\n",
            "            ReLU-207            [-1, 216, 8, 8]               0\n",
            "          Conv2d-208             [-1, 48, 8, 8]          10,368\n",
            "     BatchNorm2d-209             [-1, 48, 8, 8]              96\n",
            "            ReLU-210             [-1, 48, 8, 8]               0\n",
            "          Conv2d-211             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-212            [-1, 228, 8, 8]               0\n",
            "     BatchNorm2d-213            [-1, 228, 8, 8]             456\n",
            "            ReLU-214            [-1, 228, 8, 8]               0\n",
            "          Conv2d-215             [-1, 48, 8, 8]          10,944\n",
            "     BatchNorm2d-216             [-1, 48, 8, 8]              96\n",
            "            ReLU-217             [-1, 48, 8, 8]               0\n",
            "          Conv2d-218             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-219            [-1, 240, 8, 8]               0\n",
            "     BatchNorm2d-220            [-1, 240, 8, 8]             480\n",
            "            ReLU-221            [-1, 240, 8, 8]               0\n",
            "          Conv2d-222             [-1, 48, 8, 8]          11,520\n",
            "     BatchNorm2d-223             [-1, 48, 8, 8]              96\n",
            "            ReLU-224             [-1, 48, 8, 8]               0\n",
            "          Conv2d-225             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-226            [-1, 252, 8, 8]               0\n",
            "     BatchNorm2d-227            [-1, 252, 8, 8]             504\n",
            "            ReLU-228            [-1, 252, 8, 8]               0\n",
            "          Conv2d-229             [-1, 48, 8, 8]          12,096\n",
            "     BatchNorm2d-230             [-1, 48, 8, 8]              96\n",
            "            ReLU-231             [-1, 48, 8, 8]               0\n",
            "          Conv2d-232             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-233            [-1, 264, 8, 8]               0\n",
            "     BatchNorm2d-234            [-1, 264, 8, 8]             528\n",
            "            ReLU-235            [-1, 264, 8, 8]               0\n",
            "          Conv2d-236             [-1, 48, 8, 8]          12,672\n",
            "     BatchNorm2d-237             [-1, 48, 8, 8]              96\n",
            "            ReLU-238             [-1, 48, 8, 8]               0\n",
            "          Conv2d-239             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-240            [-1, 276, 8, 8]               0\n",
            "     BatchNorm2d-241            [-1, 276, 8, 8]             552\n",
            "            ReLU-242            [-1, 276, 8, 8]               0\n",
            "          Conv2d-243             [-1, 48, 8, 8]          13,248\n",
            "     BatchNorm2d-244             [-1, 48, 8, 8]              96\n",
            "            ReLU-245             [-1, 48, 8, 8]               0\n",
            "          Conv2d-246             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-247            [-1, 288, 8, 8]               0\n",
            "     BatchNorm2d-248            [-1, 288, 8, 8]             576\n",
            "            ReLU-249            [-1, 288, 8, 8]               0\n",
            "          Conv2d-250             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-251             [-1, 48, 8, 8]              96\n",
            "            ReLU-252             [-1, 48, 8, 8]               0\n",
            "          Conv2d-253             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-254            [-1, 300, 8, 8]               0\n",
            "     BatchNorm2d-255            [-1, 300, 8, 8]             600\n",
            "            ReLU-256            [-1, 300, 8, 8]               0\n",
            "          Conv2d-257             [-1, 48, 8, 8]          14,400\n",
            "     BatchNorm2d-258             [-1, 48, 8, 8]              96\n",
            "            ReLU-259             [-1, 48, 8, 8]               0\n",
            "          Conv2d-260             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-261            [-1, 312, 8, 8]               0\n",
            "     BatchNorm2d-262            [-1, 312, 8, 8]             624\n",
            "            ReLU-263            [-1, 312, 8, 8]               0\n",
            "          Conv2d-264             [-1, 48, 8, 8]          14,976\n",
            "     BatchNorm2d-265             [-1, 48, 8, 8]              96\n",
            "            ReLU-266             [-1, 48, 8, 8]               0\n",
            "          Conv2d-267             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-268            [-1, 324, 8, 8]               0\n",
            "     BatchNorm2d-269            [-1, 324, 8, 8]             648\n",
            "            ReLU-270            [-1, 324, 8, 8]               0\n",
            "          Conv2d-271             [-1, 48, 8, 8]          15,552\n",
            "     BatchNorm2d-272             [-1, 48, 8, 8]              96\n",
            "            ReLU-273             [-1, 48, 8, 8]               0\n",
            "          Conv2d-274             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-275            [-1, 336, 8, 8]               0\n",
            "     BatchNorm2d-276            [-1, 336, 8, 8]             672\n",
            "            ReLU-277            [-1, 336, 8, 8]               0\n",
            "          Conv2d-278             [-1, 48, 8, 8]          16,128\n",
            "     BatchNorm2d-279             [-1, 48, 8, 8]              96\n",
            "            ReLU-280             [-1, 48, 8, 8]               0\n",
            "          Conv2d-281             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-282            [-1, 348, 8, 8]               0\n",
            "     BatchNorm2d-283            [-1, 348, 8, 8]             696\n",
            "            ReLU-284            [-1, 348, 8, 8]               0\n",
            "          Conv2d-285             [-1, 48, 8, 8]          16,704\n",
            "     BatchNorm2d-286             [-1, 48, 8, 8]              96\n",
            "            ReLU-287             [-1, 48, 8, 8]               0\n",
            "          Conv2d-288             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-289            [-1, 360, 8, 8]               0\n",
            "     BatchNorm2d-290            [-1, 360, 8, 8]             720\n",
            "            ReLU-291            [-1, 360, 8, 8]               0\n",
            "          Conv2d-292             [-1, 48, 8, 8]          17,280\n",
            "     BatchNorm2d-293             [-1, 48, 8, 8]              96\n",
            "            ReLU-294             [-1, 48, 8, 8]               0\n",
            "          Conv2d-295             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-296            [-1, 372, 8, 8]               0\n",
            "     BatchNorm2d-297            [-1, 372, 8, 8]             744\n",
            "            ReLU-298            [-1, 372, 8, 8]               0\n",
            "          Conv2d-299             [-1, 48, 8, 8]          17,856\n",
            "     BatchNorm2d-300             [-1, 48, 8, 8]              96\n",
            "            ReLU-301             [-1, 48, 8, 8]               0\n",
            "          Conv2d-302             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-303            [-1, 384, 8, 8]               0\n",
            "     BatchNorm2d-304            [-1, 384, 8, 8]             768\n",
            "            ReLU-305            [-1, 384, 8, 8]               0\n",
            "          Conv2d-306            [-1, 192, 8, 8]          73,728\n",
            " TransitionBlock-307            [-1, 192, 4, 4]               0\n",
            "     BatchNorm2d-308            [-1, 192, 4, 4]             384\n",
            "            ReLU-309            [-1, 192, 4, 4]               0\n",
            "          Conv2d-310             [-1, 48, 4, 4]           9,216\n",
            "     BatchNorm2d-311             [-1, 48, 4, 4]              96\n",
            "            ReLU-312             [-1, 48, 4, 4]               0\n",
            "          Conv2d-313             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-314            [-1, 204, 4, 4]               0\n",
            "     BatchNorm2d-315            [-1, 204, 4, 4]             408\n",
            "            ReLU-316            [-1, 204, 4, 4]               0\n",
            "          Conv2d-317             [-1, 48, 4, 4]           9,792\n",
            "     BatchNorm2d-318             [-1, 48, 4, 4]              96\n",
            "            ReLU-319             [-1, 48, 4, 4]               0\n",
            "          Conv2d-320             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-321            [-1, 216, 4, 4]               0\n",
            "     BatchNorm2d-322            [-1, 216, 4, 4]             432\n",
            "            ReLU-323            [-1, 216, 4, 4]               0\n",
            "          Conv2d-324             [-1, 48, 4, 4]          10,368\n",
            "     BatchNorm2d-325             [-1, 48, 4, 4]              96\n",
            "            ReLU-326             [-1, 48, 4, 4]               0\n",
            "          Conv2d-327             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-328            [-1, 228, 4, 4]               0\n",
            "     BatchNorm2d-329            [-1, 228, 4, 4]             456\n",
            "            ReLU-330            [-1, 228, 4, 4]               0\n",
            "          Conv2d-331             [-1, 48, 4, 4]          10,944\n",
            "     BatchNorm2d-332             [-1, 48, 4, 4]              96\n",
            "            ReLU-333             [-1, 48, 4, 4]               0\n",
            "          Conv2d-334             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-335            [-1, 240, 4, 4]               0\n",
            "     BatchNorm2d-336            [-1, 240, 4, 4]             480\n",
            "            ReLU-337            [-1, 240, 4, 4]               0\n",
            "          Conv2d-338             [-1, 48, 4, 4]          11,520\n",
            "     BatchNorm2d-339             [-1, 48, 4, 4]              96\n",
            "            ReLU-340             [-1, 48, 4, 4]               0\n",
            "          Conv2d-341             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-342            [-1, 252, 4, 4]               0\n",
            "     BatchNorm2d-343            [-1, 252, 4, 4]             504\n",
            "            ReLU-344            [-1, 252, 4, 4]               0\n",
            "          Conv2d-345             [-1, 48, 4, 4]          12,096\n",
            "     BatchNorm2d-346             [-1, 48, 4, 4]              96\n",
            "            ReLU-347             [-1, 48, 4, 4]               0\n",
            "          Conv2d-348             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-349            [-1, 264, 4, 4]               0\n",
            "     BatchNorm2d-350            [-1, 264, 4, 4]             528\n",
            "            ReLU-351            [-1, 264, 4, 4]               0\n",
            "          Conv2d-352             [-1, 48, 4, 4]          12,672\n",
            "     BatchNorm2d-353             [-1, 48, 4, 4]              96\n",
            "            ReLU-354             [-1, 48, 4, 4]               0\n",
            "          Conv2d-355             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-356            [-1, 276, 4, 4]               0\n",
            "     BatchNorm2d-357            [-1, 276, 4, 4]             552\n",
            "            ReLU-358            [-1, 276, 4, 4]               0\n",
            "          Conv2d-359             [-1, 48, 4, 4]          13,248\n",
            "     BatchNorm2d-360             [-1, 48, 4, 4]              96\n",
            "            ReLU-361             [-1, 48, 4, 4]               0\n",
            "          Conv2d-362             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-363            [-1, 288, 4, 4]               0\n",
            "     BatchNorm2d-364            [-1, 288, 4, 4]             576\n",
            "            ReLU-365            [-1, 288, 4, 4]               0\n",
            "          Conv2d-366             [-1, 48, 4, 4]          13,824\n",
            "     BatchNorm2d-367             [-1, 48, 4, 4]              96\n",
            "            ReLU-368             [-1, 48, 4, 4]               0\n",
            "          Conv2d-369             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-370            [-1, 300, 4, 4]               0\n",
            "     BatchNorm2d-371            [-1, 300, 4, 4]             600\n",
            "            ReLU-372            [-1, 300, 4, 4]               0\n",
            "          Conv2d-373             [-1, 48, 4, 4]          14,400\n",
            "     BatchNorm2d-374             [-1, 48, 4, 4]              96\n",
            "            ReLU-375             [-1, 48, 4, 4]               0\n",
            "          Conv2d-376             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-377            [-1, 312, 4, 4]               0\n",
            "     BatchNorm2d-378            [-1, 312, 4, 4]             624\n",
            "            ReLU-379            [-1, 312, 4, 4]               0\n",
            "          Conv2d-380             [-1, 48, 4, 4]          14,976\n",
            "     BatchNorm2d-381             [-1, 48, 4, 4]              96\n",
            "            ReLU-382             [-1, 48, 4, 4]               0\n",
            "          Conv2d-383             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-384            [-1, 324, 4, 4]               0\n",
            "     BatchNorm2d-385            [-1, 324, 4, 4]             648\n",
            "            ReLU-386            [-1, 324, 4, 4]               0\n",
            "          Conv2d-387             [-1, 48, 4, 4]          15,552\n",
            "     BatchNorm2d-388             [-1, 48, 4, 4]              96\n",
            "            ReLU-389             [-1, 48, 4, 4]               0\n",
            "          Conv2d-390             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-391            [-1, 336, 4, 4]               0\n",
            "     BatchNorm2d-392            [-1, 336, 4, 4]             672\n",
            "            ReLU-393            [-1, 336, 4, 4]               0\n",
            "          Conv2d-394             [-1, 48, 4, 4]          16,128\n",
            "     BatchNorm2d-395             [-1, 48, 4, 4]              96\n",
            "            ReLU-396             [-1, 48, 4, 4]               0\n",
            "          Conv2d-397             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-398            [-1, 348, 4, 4]               0\n",
            "     BatchNorm2d-399            [-1, 348, 4, 4]             696\n",
            "            ReLU-400            [-1, 348, 4, 4]               0\n",
            "          Conv2d-401             [-1, 48, 4, 4]          16,704\n",
            "     BatchNorm2d-402             [-1, 48, 4, 4]              96\n",
            "            ReLU-403             [-1, 48, 4, 4]               0\n",
            "          Conv2d-404             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-405            [-1, 360, 4, 4]               0\n",
            "     BatchNorm2d-406            [-1, 360, 4, 4]             720\n",
            "            ReLU-407            [-1, 360, 4, 4]               0\n",
            "          Conv2d-408             [-1, 48, 4, 4]          17,280\n",
            "     BatchNorm2d-409             [-1, 48, 4, 4]              96\n",
            "            ReLU-410             [-1, 48, 4, 4]               0\n",
            "          Conv2d-411             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-412            [-1, 372, 4, 4]               0\n",
            "     BatchNorm2d-413            [-1, 372, 4, 4]             744\n",
            "            ReLU-414            [-1, 372, 4, 4]               0\n",
            "          Conv2d-415             [-1, 48, 4, 4]          17,856\n",
            "     BatchNorm2d-416             [-1, 48, 4, 4]              96\n",
            "            ReLU-417             [-1, 48, 4, 4]               0\n",
            "          Conv2d-418             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-419            [-1, 384, 4, 4]               0\n",
            "     BatchNorm2d-420            [-1, 384, 4, 4]             768\n",
            "            ReLU-421            [-1, 384, 4, 4]               0\n",
            "          Linear-422                   [-1, 10]           3,850\n",
            "================================================================\n",
            "Total params: 1,000,618\n",
            "Trainable params: 1,000,618\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 43.32\n",
            "Params size (MB): 3.82\n",
            "Estimated Total Size (MB): 47.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}